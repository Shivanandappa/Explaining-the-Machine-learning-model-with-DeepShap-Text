{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb6bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de55713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
      "     ------------------------------------ 745.3/745.3 kB 130.0 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML in c:\\users\\petro\\appdata\\roaming\\python\\python38\\site-packages (from pyngrok) (6.0)\n",
      "Building wheels for collected packages: pyngrok\n",
      "  Building wheel for pyngrok (setup.py): started\n",
      "  Building wheel for pyngrok (setup.py): finished with status 'done'\n",
      "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19005 sha256=112484ad825e46b447b540501dc22bd471454ff384bdb548fea66735a52d291a\n",
      "  Stored in directory: c:\\users\\petro\\appdata\\local\\pip\\cache\\wheels\\87\\a1\\e7\\66d10d257852cd702f8e56be9aa70e74d8ac90f8d951eaa984\n",
      "Successfully built pyngrok\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745e42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "from streamlit_shap import st_shap\n",
    "import shap\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "#title\n",
    "st.title('Flights Sentiment Analysis project by JAY & PETRO')\n",
    "\n",
    "#markdown text \n",
    "st.markdown(\"This dashboard is about visualisation flight review\")\n",
    "\n",
    "#sidebar top\n",
    "st.sidebar.title('Sentiment analysis of Flights')\n",
    "                 \n",
    "# sidebar markdown \n",
    "st.sidebar.markdown(\"We can analyse passengers review from this application\")\n",
    "\n",
    "data = pd.read_csv('review.csv')\n",
    "\n",
    "\n",
    "#checkbox to show data .. check box is true .. show the data\n",
    "if st.checkbox(\"Show Data\"):\n",
    "    st.write(data.head(50)) # head count 50\n",
    "\n",
    "    \n",
    "#Radio buttons + Visualisation\n",
    "\n",
    "select = st.sidebar.selectbox('Visulisation of Tweets',['Histogram','Pie chart'],key=1) # another widget another key\n",
    "\n",
    "sentiment = data['airline_sentiment'].value_counts()\n",
    "sentiment=pd.DataFrame({'Sentiment':sentiment.index,'Tweets':sentiment.values})\n",
    "st.markdown(\"### Sentiment count\")\n",
    "if select == \"Histogram\":\n",
    "        fig = px.bar(sentiment, x='Sentiment', y='Tweets', color = 'Tweets', height= 500) #plotly library\n",
    "        st.plotly_chart(fig)\n",
    "else:\n",
    "        fig = px.pie(sentiment, values='Tweets', names='Sentiment')\n",
    "        st.plotly_chart(fig)\n",
    "               \n",
    "    \n",
    "#subheader with radiobuttons\n",
    "st.sidebar.subheader('Tweets Analyser map')\n",
    "tweets=st.sidebar.radio('Sentiment Type',('positive','negative','neutral')) # the data will take from the airline sentiment column \n",
    "\n",
    "st.markdown(\"Some Tweet review:\")\n",
    "# Comment section \n",
    "st.write(data.query('airline_sentiment==@tweets')[['text']].sample(1).iat[0,0])  \n",
    "st.write(data.query('airline_sentiment==@tweets')[['text']].sample(1).iat[0,0])\n",
    "st.write(data.query('airline_sentiment==@tweets')[['text']].sample(1).iat[0,0])\n",
    "\n",
    "\n",
    "# Slider side\n",
    "st.sidebar.markdown('Time & location of tweets')\n",
    "hr = st.sidebar.slider(\"Houe of the day\",0,23)\n",
    "data['Date'] = pd.to_datetime(data['tweet_created']) #Pandas dataframe for time \n",
    "hr_data = data[data['Date'].dt.hour == hr]\n",
    "\n",
    "if not st.sidebar.checkbox(\"Hide\",False, key='1'):\n",
    "    st.markdown(\"### location of the tweets based on the hour of the day\")\n",
    "    st.markdown(\"%i tweets during %i:00 and %i:00\" % (len(hr_data),hr,(hr+1)%24))\n",
    "    st.map(hr_data)\n",
    "    \n",
    "\n",
    "#MULSELECT SLIDER\n",
    "st.sidebar.subheader(\"Airline tweets by sentiment\")\n",
    "choice = st.sidebar.multiselect(\"Airlines\", ('US Airways', 'United', 'American', 'Southwest', 'Delta', 'Virgin America'), key = '0')  \n",
    "if len(choice)>0:\n",
    "    air_data=data[data.airline.isin(choice)]\n",
    "    # facet_col = 'airline_sentiment'\n",
    "    fig1 = px.histogram(air_data, x='airline', y='airline_sentiment', histfunc='count', color='airline_sentiment',labels={'airline_sentiment':'tweets'}, height=600, width=800)\n",
    "    st.plotly_chart(fig1)  \n",
    "    \n",
    "# Load the model for shap \n",
    "# load YAML and create model\n",
    "yaml_file = open(r\"C:\\Users\\Petro\\Desktop\\Visual Analytics\\Visual_Analytics\\model.yaml\", 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(r\"C:\\Users\\Petro\\Desktop\\Visual Analytics\\Visual_Analytics\\model.h5\")\n",
    "\n",
    "# Load in Data for Shap\n",
    "sentences_test = pd.read_csv(\"sentences_test.csv\")\n",
    "sentences_test = sentences_test.squeeze()\n",
    "\n",
    "# load vectorizer\n",
    "vectorizer = pickle.load(open(\"vectorizer.pk\", \"rb\"))\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "#load X_test\n",
    "X_test= pd.read_csv(\"X_test.csv\")\n",
    "# method to make prediction for shap \n",
    "def make_predictions(X_batch_text):\n",
    "    X_batch = vectorizer.transform(X_batch_text).toarray()\n",
    "    preds = loaded_model.predict(X_batch)\n",
    "    return preds\n",
    "\n",
    "\n",
    "selected_categories=['negative','neutral','positive']\n",
    "masker = shap.maskers.Text(tokenizer=r\"\\W+\")\n",
    "explainer = shap.Explainer(make_predictions, masker=masker, output_names=selected_categories)\n",
    "\n",
    "\n",
    "\n",
    "X_batch_text = sentences_test[1:5]\n",
    "X_batch = X_test[1:5]\n",
    "\n",
    "\n",
    "shap_values = explainer(X_batch_text)\n",
    "\n",
    "\n",
    "st_shap(shap.text_plot(shap_values),height=2000, width=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ea28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c6dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
